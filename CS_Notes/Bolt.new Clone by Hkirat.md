Link ->https://www.youtube.com/watch?v=ofHGE-85EIA
Continue from 18:00 .

- It is a `GPT Wrapper`.
- So, basically we send API calls from our backend to any LLM Model which does the heavy lifting of the code.
- We basically parse response and display it in a pretty UI.
- For building something like `Bolt` or `v0`, we are returned some steps which our backend needs to understand and execute in given order.

### Where do we execute the returned code?

- Either use `WebContainers` or deploy on your own infrastructure like say `Replit`.
- `WebContainers` run inside the browser.

>[!BILLION DOLLAR IDEA] **Using TEE's to execute testcases inside user env itself.**





